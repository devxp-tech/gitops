apiVersion: opentelemetry.io/v1alpha1
kind: OpenTelemetryCollector
metadata:
  name: otel
  namespace: observability
spec:
  mode: deployment
  config: |
    extensions:
      health_check:
      pprof:
      zpages:
    receivers:
      jaeger:
        protocols:
          grpc:
          thrift_http:
          thrift_compact:
      otlp:
        protocols:
          grpc:
          http:
      zipkin:


    processors:
      memory_limiter:
        check_interval: 1s
        limit_percentage: 75
        spike_limit_percentage: 15
      batch:
        send_batch_size: 10000
        timeout: 10s
      spanmetrics:
        metrics_exporter: prometheus
      servicegraph:
        metrics_exporter: prometheus # Exporter to send metrics to
        latency_histogram_buckets: [100us, 1ms, 2ms, 6ms, 10ms, 100ms, 250ms] # Buckets for latency histogram
        dimensions: [cluster, namespace, operation,service_name] # Additional dimensions (labels) to be added to the metrics extracted from the resource and span attributes
        store: # Configuration for the in-memory store
          ttl: 2s # Value to wait for an edge to be completed
          max_items: 200 # Amount of edges that will be stored in the storeMap

    exporters:
      logging:
      # otlphttp:
      #   endpoint: http://tempo.observability.svc.cluster.local:4318
      #   tls:
      #     insecure: true
      otlp/tempo:
        endpoint: "tempo.observability.svc:4317"
        tls:
          insecure: true

    service:
      extensions: [health_check, pprof, zpages]
      pipelines:
        traces:
          receivers: [jaeger, otlp, zipkin]
          processors: [servicegraph , spanmetrics, memory_limiter, batch]
          exporters: [logging, otlp/tempo]
        metrics:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters: [logging]
        logs:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters: [logging]
