apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
namespace: logging
helmCharts:
  - name: loki
    includeCRDs: true
    releaseName: loki
    namespace: logging
    version: 6.6.3 #2.9.11
    repo: https://grafana.github.io/helm-charts
    valuesInline:
      serviceAccount:
        name: loki
        annotations:
          "eks.amazonaws.com/role-arn": "arn:aws:iam::239468932737:role/loki-lgseksd1-sa"
        automountServiceAccountToken: true
      lokiCanary:
        enabled: false
      monitoring:
        serviceMonitor:
          enabled: true
        dashboards:
          enabled: true
          namespace: monitoring
        selfMonitoring:
          enabled: false
          grafanaAgent:
            installOperator: false
      chunksCache:
        resources:
          requests:
            memory: 77Mi
            cpu: 10m
          limits:
            memory: 256Mi
            cpu: 200m
      resultsCache:
        resources:
          requests:
            memory: 20Mi
            cpu: 10m
          limits:
            memory: 256Mi
            cpu: 100m
      test:
        enabled: false
      persistence:
        enabled: true
      ruler:
        enabled: true
        extraVolumes:
        - name: loki-rules-generated
          emptyDir: {}
        extraVolumeMounts:
        - name: loki-rules-generated
          mountPath: /rules
        directories:
          fake:
            rules.yaml: |
              groups:
                - name: should_fire
                  rules:
                    - alert: HighPercentageError
                      expr: |
                        sum(rate({app="foo", env="production"} |= "error" [5m])) by (job)
                          /
                        sum(rate({app="foo", env="production"}[5m])) by (job)
                          > 0.05
                      for: 10m
                      labels:
                          severity: page
                      annotations:
                          summary: High request latency
                - name: credentials_leak
                  rules:
                    - alert: http-credentials-leaked
                      annotations:
                        message: "{{ $labels.job }} is leaking http basic auth credentials."
                      expr: 'sum by (cluster, job, pod) (count_over_time({namespace="prod"} |~ "http(s?)://(\\w+):(\\w+)@" [5m]) > 0)'
                      for: 10m
                      labels:
                        severity: critical
        extraEnv:
          - name: JAEGER_AGENT_HOST
            value: otel-collector.observability.svc.cluster.local
          - name: JAEGER_AGENT_PORT
            value: "6831"
          - name: JAEGER_SAMPLER_TYPE
            value: const
          - name: JAEGER_SAMPLER_PARAM
            value: "1"
      backend:
        replicas: 2
        extraEnv:
          - name: JAEGER_AGENT_HOST
            value: otel-collector.observability.svc.cluster.local
          - name: JAEGER_AGENT_PORT
            value: "6831"
          - name: JAEGER_SAMPLER_TYPE
            value: const
          - name: JAEGER_SAMPLER_PARAM
            value: "1"
      read:
        replicas: 2
        extraEnv:
          - name: JAEGER_AGENT_HOST
            value: otel-collector.observability.svc.cluster.local
          - name: JAEGER_AGENT_PORT
            value: "6831"
          - name: JAEGER_SAMPLER_TYPE
            value: const
          - name: JAEGER_SAMPLER_PARAM
            value: "1"
      write:
        replicas: 2
        extraEnv:
          - name: JAEGER_AGENT_HOST
            value: otel-collector.observability.svc.cluster.local
          - name: JAEGER_AGENT_PORT
            value: "6831"
          - name: JAEGER_SAMPLER_TYPE
            value: const
          - name: JAEGER_SAMPLER_PARAM
            value: "1"
      # sidecar:
      #   rules:
      #     label: loki_rule
      #     labelValue: 'true'
      #     folder: /rules/fake
      #     searchNamespace: ALL
      #     resource: configmap
      loki:
        auth_enabled: false
        commonConfig:
          replication_factor: 1
        storage:
          type: s3
          s3ForcePathStyle: true
          s3:
            region: us-east-1
          bucketNames:
            chunks: "vex-dev-loki-logs"
            ruler: "vex-dev-loki-logs"
            admin: "vex-dev-loki-logs"
        structuredConfig:
          ruler:
            wal:
              dir: /tmp/loki/ruler-wal
            storage:
              type: local
              local:
                directory: /etc/loki/rules
            rule_path: /tmp/loki/rules
            remote_write:
              enabled: true
              client:
                url: http://mimir-nginx.monitoring.svc.cluster.local/api/v1/push
        ingester:
          autoforget_unhealthy: true
        alertmanager_url: http://prometheus-community-kube-alertmanager.monitoring.svc.cluster.local:9093
        external_url: "https://alertmanager.devxp-tech.io"
        enable_alertmanager_discovery: true
        enable_alertmanager_v2: true
        enable_api: true
        datasource_uid: "loki"
        schemaConfig:
          configs:
            - from: "2024-04-01"
              index:
                period: 24h
                prefix: index_
              object_store: s3
              schema: v13
              store: tsdb
        limits_config:
          ingestion_rate_mb: 8
          ingestion_burst_size_mb: 16
          max_cache_freshness_per_query: 10m
          retention_period: 7d
          reject_old_samples: true
          reject_old_samples_max_age: 168h
          split_queries_by_interval: 15m
        query_scheduler:
          max_outstanding_requests_per_tenant: 2048
        querier:
          max_concurrent: 20
        tracing:
          enabled: true
